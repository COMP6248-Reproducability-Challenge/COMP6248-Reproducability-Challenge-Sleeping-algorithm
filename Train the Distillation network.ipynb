{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchbearer\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torchbearer.callbacks import LiveLossPlot\n",
    "from itertools import product\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert to tensor\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # flatten into vector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
    "testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
    "#split the data\n",
    "trainset.data = trainset.data[0:27105]\n",
    "trainset.targets = trainset.targets[0:27105]\n",
    "# # print(trainset.targets[0:11905])\n",
    "#for distillation\n",
    "trainloaderforDistillation = DataLoader(trainset, batch_size=1000, shuffle=True)\n",
    "testloaderforDistillation = DataLoader(testset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterCNNforDistillation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterCNNforDistillation, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3, 3), padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 5**2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = F.dropout(out, 0.2)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 63.46\n",
      "Epoch 1, loss 57.52\n",
      "**** Finished Training ****\n"
     ]
    }
   ],
   "source": [
    "#train distillion network\n",
    "\n",
    "modelDistillation = BetterCNNforDistillation().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimiser = optim.Adam(model.parameters())\n",
    "optimiser = optim.SGD(modelDistillation.parameters(), lr=0.1, momentum=0.5)\n",
    "running_loss = 0.0\n",
    "\n",
    "#teacher network\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for data in trainloaderforDistillation:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = torch.reshape(inputs, [-1, 1,28,28])\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # forward + loss + backward + optimise (update weights)\n",
    "        outputs = modelDistillation(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        #update the label for modelDistillation\n",
    "        if epoch == 1:       \n",
    "            predictions = torch.argmax(outputs, 1)\n",
    "            labels = predictions\n",
    "            \n",
    "        \n",
    "        # keep track of the loss this epoch\n",
    "        running_loss += loss.item()\n",
    "    print(\"Epoch %d, loss %4.2f\" % (epoch, running_loss))\n",
    "print('**** Finished Training ****')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 29.56\n",
      "Epoch 1, loss 8.95\n",
      "**** Finished Training ****\n"
     ]
    }
   ],
   "source": [
    "#student network\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for data in trainloaderforDistillation:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = torch.reshape(inputs, [-1, 1,28,28])\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # forward + loss + backward + optimise (update weights)\n",
    "        outputs = modelDistillation(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step() \n",
    "        \n",
    "        # keep track of the loss this epoch\n",
    "        running_loss += loss.item()\n",
    "    print(\"Epoch %d, loss %4.2f\" % (epoch, running_loss))\n",
    "print('**** Finished Training ****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.93 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BetterCNNforDistillation. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "modelDistillation.eval()\n",
    "\n",
    "# Compute the model accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloaderforDistillation:\n",
    "    inputs, labels = data\n",
    "    inputs = torch.reshape(inputs, [-1, 1,28,28])\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = modelDistillation(inputs)\n",
    "    predictions = torch.argmax(outputs, 1)\n",
    "    correct += (predictions == labels).sum().float()\n",
    "    total += len(labels)\n",
    "print('Test Accuracy: %2.2f %%' % ((100.0 * correct) / total))\n",
    "torch.save(modelDistillation,'save_dis.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
