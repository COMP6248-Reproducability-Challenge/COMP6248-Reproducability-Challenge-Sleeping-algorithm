# -*- coding: utf-8 -*-
"""Distortion Networks FGSM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1siefQmGlIlnn746vVsSTS0JXre7uGcV2
"""

import torch
import torchbearer
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch import nn
from torch import optim
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
import numpy as np
import pickle
from torchbearer.callbacks import LiveLossPlot
from itertools import product
import gc
from scipy.ndimage import gaussian_filter
import numpy as np
from matplotlib import pyplot as plt
import random
import torch.nn.functional as F
from torch import nn
import sys
import torchvision.utils
from torchvision import models
import torchvision.datasets as dsets
import torchvision.transforms as transforms

# fix random seed for reproducibility
seed = 7
torch.manual_seed(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(seed)
device = "cuda:0" if torch.cuda.is_available() else "cpu"

# flatten 28*28 images to a 784 vector for each image
transform = transforms.Compose([
    transforms.ToTensor(),  # convert to tensor
    transforms.Lambda(lambda x: x.view(-1))  # flatten into vector
])

# define baseline model
class BaselineModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(BaselineModel, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size) 
        self.fc2 = nn.Linear(hidden_size, hidden_size) 
        self.fc3 = nn.Linear(hidden_size, num_classes)  
    
    def forward(self, x):
        out = self.fc1(x)
        out = F.relu(out)
        out = F.dropout(out, 0.2)        
        out = self.fc2(out)        
        out = F.relu(out)
        out = self.fc3(out)
        if not self.training:
            out = F.softmax(out, dim=1)
        return out
    
# Define the ANN  network
class NetworkControl(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NetworkControl, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size) 
        self.fc2 = nn.Linear(hidden_size, hidden_size) 
        self.fc3 = nn.Linear(hidden_size, num_classes)  
    
    def forward(self, x):
        out = self.fc1(x)
        out = F.relu(out)
        out = F.dropout(out, 0.2)        
        out = self.fc2(out)        
        out = F.relu(out)
        out = F.dropout(out, 0.2)        
        out = self.fc3(out)
        if not self.training:
            out = F.softmax(out, dim=1)
        return out
    
    
class BetterCNNforDistillation(nn.Module):
    def __init__(self):
        super(BetterCNNforDistillation, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)
        self.conv2 = nn.Conv2d(32, 64, (3, 3), padding=0)
        self.fc1 = nn.Linear(64 * 5**2, 1024)
        self.fc2 = nn.Linear(1024, 50)
        self.fc3 = nn.Linear(50, 10)

            
    def forward(self, x):
        out = self.conv1(x)
        out = F.relu(out)
        out = F.max_pool2d(out, (2,2))
        out = self.conv2(out)
        out = F.relu(out)
        out = F.max_pool2d(out, (2,2))
        out = F.dropout(out, 0.2)
        out = out.view(out.shape[0], -1)
        out = self.fc1(out)
        out = F.relu(out)
        out = self.fc2(out)
        out = F.relu(out)
        out = self.fc3(out)
        if not self.training:
            out = F.softmax(out, dim=1)
        return out

def fgsm_attack(model, loss, images, labels, eps) :
    
    images = images.to(device)
    labels = labels.to(device)
    images.requires_grad = True
            
    outputs = model(images)
    
    model.zero_grad()
    cost = loss(outputs, labels).to(device)
    cost.backward()
    
    attack_images = images + eps*images.grad.sign()
    attack_images = torch.clamp(attack_images, 0, 1)
    
    return attack_images

#plot

trainset = MNIST(".", train=True, download=True, transform=transform)
testset = MNIST(".", train=False, download=True, transform=transform)
trainset.data = trainset.data[0:27105]
trainset.targets = trainset.targets[0:27105]


sigma_values = [0, 0.5, 1.0, 1.5, 2.0, 2.5]
variance_values = [0, 0.2, 0.4, 0.6, 0.8, 1.0]
blur_acc_control = []
blur_acc_sleep = []
blur_acc_finetune_noise = []
blur_acc_finetune_blur = []
blur_acc_dis = []
noise_acc_control = []
noise_acc_sleep = []
noise_acc_finetune_noise = []
noise_acc_finetune_blur = []
noise_acc_dis = []

for i in range(len(sigma_values)):
    
    j = i
    
    #blur data
    trainset = MNIST(".", train=True, download=True, transform=transform)
    testset = MNIST(".", train=False, download=True, transform=transform)
    trainset.data = trainset.data[0:27105]
    trainset.targets = trainset.targets[0:27105]



    # function to blur each MNIST image
    def blur(x, sig):
        return gaussian_filter(x, sigma=sig)
    

    # Distort the test set #
    for i in range(len(testset)):
        # gaussian blur the image with the chosen sigma value
        blurredImage = blur(testset.test_data[i].numpy(), sigma_values[j])
        # update the training set with the blurred image
        testset.test_data[i] = torch.from_numpy(blurredImage)
    
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128, shuffle=True)
    
    #test the controlled network
    model = torch.load('save_ann.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    # trial = torchbearer.Trial(model, optimiser, loss_function, callbacks=[live_loss_plot], metrics=['loss', 'accuracy']).to(device)
    trial = torchbearer.Trial(model, optimiser, loss_function,metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    blur_acc_control.append(100.0 * results["test_acc"])
    
    #test the sleeping network
    model = torch.load('save_sleep.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    # trial = torchbearer.Trial(model, optimiser, loss_function, callbacks=[live_loss_plot], metrics=['loss', 'accuracy']).to(device)
    trial = torchbearer.Trial(model, optimiser, loss_function,metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    blur_acc_sleep.append(100.0 * results["test_acc"])
    
    #test the fine-tuning-blur network
    model = torch.load('save_blur.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    blur_acc_finetune_blur.append(100.0 * results["test_acc"])
    
    #test the fine-tuning-noise network
    model = torch.load('save_noise.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    blur_acc_finetune_noise.append(100.0 * results["test_acc"])
    
    #test the distillion network
    model = torch.load('save_dis.pkl')
    model.eval()

    # Compute the model accuracy on the test set
    correct = 0
    total = 0

    for data in testloader:
        inputs, labels = data
        inputs = torch.reshape(inputs, [-1, 1,28,28])
        inputs = inputs.to(device)
        labels = labels.to(device)
        outputs = model(inputs)
        predictions = torch.argmax(outputs, 1)
        correct += (predictions == labels).sum().float()
        total += len(labels)
    print('Test Accuracy: %2.2f %%' % ((100.0 * correct) / total))
    blur_acc_dis.append(((100.0 * correct) / total).item())
    
    
    
    #noise data
    trainset = MNIST(".", train=True, download=True, transform=transform)
    testset = MNIST(".", train=False, download=True, transform=transform)
    trainset.data = trainset.data[0:27105]
    trainset.targets = trainset.targets[0:27105]
    
    def noise(x, var):
        return x + var * x.std() * np.random.random(x.shape)

    for i in range(len(testset)):
        # add gaussian noise to the image with the chosen variance value
        noisyImage = noise(testset.test_data[i].numpy(), variance_values[j])
        # update the training set with the noise image
        testset.test_data[i] = torch.from_numpy(noisyImage)
    
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128, shuffle=True)
    
    #test the controlled network
    model = torch.load('save_ann.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    noise_acc_control.append(100.0 * results["test_acc"])
    
    #test the sleeping network
    model = torch.load('save_sleep.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    noise_acc_sleep.append(100.0 * results["test_acc"])
    
    #test the fine-tuning-blur network
    model = torch.load('save_blur.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    noise_acc_finetune_blur.append(100.0 * results["test_acc"])
    
    #test the fine-tuning-noise network
    model = torch.load('save_noise.pkl')
    loss_function = nn.CrossEntropyLoss()
    # live_loss_plot = LiveLossPlot()
    optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
    trial = torchbearer.Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)
    trial.with_generators(trainloader, test_generator=testloader)
    results = trial.evaluate(data_key=torchbearer.TEST_DATA)
    print(results)
    noise_acc_finetune_noise.append(100.0 * results["test_acc"])
    
    #test the distillion network
    model = torch.load('save_dis.pkl')
    model.eval()
    # Compute the model accuracy on the test set
    correct = 0
    total = 0
    for data in testloader:
        inputs, labels = data
        inputs = torch.reshape(inputs, [-1, 1,28,28])
        inputs = inputs.to(device)
        labels = labels.to(device)
        outputs = model(inputs)
        predictions = torch.argmax(outputs, 1)
        correct += (predictions == labels).sum().float()
        total += len(labels)
    print('Test Accuracy: %2.2f %%' % ((100.0 * correct) / total))
    noise_acc_dis.append(((100.0 * correct) / total).item())

plt.plot(sigma_values, blur_acc_control, label='Control')
plt.plot(sigma_values, blur_acc_sleep, label='Sleep')
plt.plot(sigma_values, blur_acc_finetune_noise, label='Finetune-noise')
plt.plot(sigma_values, blur_acc_finetune_blur, label='Finetune-blur')
plt.plot(sigma_values, blur_acc_dis, label='Dif.Dist')
plt.legend()
plt.show()

plt.plot(variance_values, noise_acc_control, label='Control')
plt.plot(variance_values, noise_acc_sleep, label='Sleep')
plt.plot(variance_values, noise_acc_finetune_noise, label='Finetune-noise')
plt.plot(variance_values, noise_acc_finetune_blur, label='Finetune-blur')
plt.plot(variance_values, noise_acc_dis, label='Dif.Dist')
plt.legend()
plt.show()

eps = [0,0.04,0.08,0.12,0.16,0.2]
fgsm_acc_control = []
fgsm_acc_sleep = []
fgsm_acc_finetune_noise = []
fgsm_acc_finetune_blur = []
fgsm_acc_dis = []
for i in range(len(eps)):
     #FGSM   
    print("Attack Image & Predicted Label")
    loss_function = nn.CrossEntropyLoss()

    

    trainset = MNIST(".", train=True, download=True, transform=transform)
    testset = MNIST(".", train=False, download=True, transform=transform)
    trainset.data = trainset.data[0:27105]
    trainset.targets = trainset.targets[0:27105]
    trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
    testloader = DataLoader(testset, batch_size=128, shuffle=True)
    
    
    model = torch.load('save_ann.pkl')
    model.eval()
    loss_function = nn.CrossEntropyLoss()
    correct = 0
    total = 0
    for images, labels in testloader:
    
        images = fgsm_attack(model, loss_function, images, labels, eps[i]).to(device)
        labels = labels.to(device)
        outputs = model(images)

        _, pre = torch.max(outputs.data, 1)

        total += labels.shape[0]
        correct += (pre == labels).sum()
    
    #     imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])
    
    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))
    fgsm_acc_control.append(100 * float(correct) / total)
    
    model = torch.load('save_sleep.pkl')
    model.eval()
    loss_function = nn.CrossEntropyLoss()
    correct = 0
    total = 0
    for images, labels in testloader:
    
        images = fgsm_attack(model, loss_function, images, labels, eps[i]).to(device)
        labels = labels.to(device)
        outputs = model(images)

        _, pre = torch.max(outputs.data, 1)

        total += labels.shape[0]
        correct += (pre == labels).sum()
    
    #     imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])
    
    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))
    fgsm_acc_sleep.append(100 * float(correct) / total)
    
    model = torch.load('save_noise.pkl')
    model.eval()
    loss_function = nn.CrossEntropyLoss()
    correct = 0
    total = 0
    for images, labels in testloader:
    
        images = fgsm_attack(model, loss_function, images, labels, eps[i]).to(device)
        labels = labels.to(device)
        outputs = model(images)

        _, pre = torch.max(outputs.data, 1)

        total += labels.shape[0]
        correct += (pre == labels).sum()
    
    #     imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])
    
    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))
    fgsm_acc_finetune_noise.append(100 * float(correct) / total)
    
    model = torch.load('save_blur.pkl')
    model.eval()
    loss_function = nn.CrossEntropyLoss()
    correct = 0
    total = 0
    for images, labels in testloader:
    
        images = fgsm_attack(model, loss_function, images, labels, eps[i]).to(device)
        labels = labels.to(device)
        outputs = model(images)

        _, pre = torch.max(outputs.data, 1)

        total += labels.shape[0]
        correct += (pre == labels).sum()
    
    #     imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])
    
    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))
    fgsm_acc_finetune_blur.append(100 * float(correct) / total)
    
    model = torch.load('save_dis.pkl')
    model.eval()
    loss_function = nn.CrossEntropyLoss()
    correct = 0
    total = 0
    for images, labels in testloader:
        images = torch.reshape(images, [-1, 1,28,28])
        images = fgsm_attack(model, loss_function, images, labels, eps[i]).to(device)
        labels = labels.to(device)
        outputs = model(images)

        _, pre = torch.max(outputs.data, 1)

        total += labels.shape[0]
        correct += (pre == labels).sum()
    
    #     imshow(torchvision.utils.make_grid(images.cpu().data, normalize=True), [normal_data.classes[i] for i in pre])
    
    print('Accuracy of test text: %f %%' % (100 * float(correct) / total))
    fgsm_acc_dis.append(100 * float(correct) / total)

plt.errorbar(eps, fgsm_acc_control, label='Control')
plt.plot(eps, fgsm_acc_sleep, label='Sleep')
plt.plot(eps, fgsm_acc_finetune_noise, label='Finetune-noise')
plt.plot(eps, fgsm_acc_finetune_blur, label='Finetune-blur')
plt.plot(eps, fgsm_acc_dis, label='Dif.Dist')
plt.legend()
plt.show()