# -*- coding: utf-8 -*-
"""ControlNetwork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mkrZ9RaBHzvatEA4wa5S82J2E4KfmU-P
"""

import torch
import torchbearer
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch import nn
from torch import optim
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
import numpy as np
import pickle
from torchbearer.callbacks import LiveLossPlot
from itertools import product
from scipy.ndimage import gaussian_filter
import numpy as np
from matplotlib import pyplot as plt
import random
import torch.nn.functional as F
from torch import nn

# fix random seed for reproducibility
seed = 7
torch.manual_seed(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(seed)
device = "cuda:0" if torch.cuda.is_available() else "cpu"

transform = transforms.Compose([
    transforms.ToTensor(),  # convert to tensor
    transforms.Lambda(lambda x: x.view(-1))  # flatten into vector
])

# RE-RUN CELL TO RESET DISTORTIONS MADE TO MNIST DATASET #

# load MNIST data into training and test sets
trainset = MNIST(".", train=True, download=True, transform=transform)
testset = MNIST(".", train=False, download=True, transform=transform)
trainset.data = trainset.data[0:27105]
trainset.targets = trainset.targets[0:27105]

# Create the data loaders for the training and test sets
trainloader = DataLoader(trainset, batch_size=128, shuffle=True)
testloader = DataLoader(testset, batch_size=128, shuffle=True)

import torch.nn.functional as F
from torch import nn

# Define the ANN
class NetworkControl(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NetworkControl, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size) 
        self.fc2 = nn.Linear(hidden_size, hidden_size) 
        self.fc3 = nn.Linear(hidden_size, num_classes)  
    
    def forward(self, x):
        out = self.fc1(x)
        out = F.relu(out)
        out = F.dropout(out, 0.2)        
        out = self.fc2(out)        
        out = F.relu(out)
        out = F.dropout(out, 0.2)        
        out = self.fc3(out)
        if not self.training:
            out = F.softmax(out, dim=1)
        return out

# initialize control network
model = NetworkControl(784, 1200, 10)

# define the loss function
loss_function = nn.CrossEntropyLoss()
# define the optimiser, learning rate and momentum
optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)

# create a live loss plot of accuracy and loss after each training epoch
plot = LiveLossPlot()

# train the network using model, optimiser and loss function for 2 epochs
trial = torchbearer.Trial(model, optimiser, loss_function, callbacks=[plot], metrics=['loss', 'accuracy']).to(device)
trial.with_generators(trainloader, test_generator=testloader)
trial.run(epochs=2)

results = trial.evaluate(data_key=torchbearer.TEST_DATA)
print(results)

torch.save(model,'save_ann.pkl')